# leverage research: composite score composition (v8)

this document explores different methods for composing dimensional metrics into a single composite leverage score, and analyzes their consequences on relative tool rankings.


---


## 0. leverage dimension structure

```
leverage.composite/week
├── leverage.author/week = leverage.author/use × freq
│   └── leverage.author/use = (α × time.gut) + ((1-α) × time.decomposed)
│       ├── leverage.author.time      [save, mins/use]  ← gut estimate
│       ├── leverage.author.code.block [save, blocks/use] ─┐
│       ├── leverage.author.code.path  [save, paths/use]  ├─ decomposed
│       └── leverage.author.khue       [save, khues/use] ─┘
│
├── leverage.support/week = leverage.support/fail × fail.rate
│   └── leverage.support/fail = (α × time.gut) + ((1-α) × time.decomposed)
│       ├── leverage.support.time     [save, mins/fail]  ← gut estimate
│       ├── leverage.support.signal   [gain, signals/use] ─┐
│       └── leverage.support.defence  [gain, defences/use] ┴─ decomposed
│
└── leverage.adopt
    ├── leverage.adopt.freq           [—, uses/week]     ← scaling factor
    └── leverage.adopt.time           [cost, mins/tool]  ← amortized over 52 weeks
```

**symmetry:** author and support are treated identically:
- both have a gut time estimate
- both have sub-dimensions that decompose into time
- both compose via: `(α × gut) + ((1-α) × decomposed)`
- both scale to weekly: `× freq` for author, `× fail.rate` for support


---


## 1. time as the fundamental unit of leverage

### 1.1. why time?

in software, all leverage ultimately reduces to time:

- **code blocks** = time saved writing and debugging
- **decision points (khues)** = time saved researching and deciding
- **signals** = time saved diagnosing
- **defences** = time saved preventing and recovering

even seemingly non-temporal metrics (complexity, cognitive load, risk) are proxies for time: how long would it take to understand, fix, or recover?


### 1.2. the thermodynamic grounding

this isn't arbitrary — it's physically grounded:

```
energy = time × entropy rate

where:
  energy = capacity to do work
  entropy rate = rate of state-space exploration
  time = the fundamental dimension
```

in software terms:
- **energy** = developer hours available
- **entropy rate** = rate at which problems are solved (decisions made, code written)
- **time** = the irreducible constraint

a tool that saves 1 hour of work has saved 1 hour of the universe's most scarce resource: irreversible time. this is why we normalize all leverage dimensions to time-equivalents.


### 1.3. implication for composition

because all leverage reduces to time, we can:
1. convert any metric to time-equivalent (mins saved)
2. add time-equivalents directly (apples to apples)
3. weight by frequency to get time saved per week
4. compare tools on a single, meaningful scale


---


## 2. the composition challenge

v7 established 9 dimensional metrics across 3 lifecycles. to compare tools, we need a single composite score. but:

- **author vs support**: how do we weight development time savings vs operational time savings?
- **gut vs decomposed**: leverage.author.time is a "gut feeling" estimate; blocks/paths/khues are decomposed. which do we trust?
- **frequency scaling**: how does leverage.adopt.freq affect the composite?
- **adoption cost**: when and how do we subtract leverage.adopt.time?


---


## 3. raw measurements from v7

### 3.1. with-simple-cache

| metric | polarity | value |
|--------|----------|-------|
| leverage.author.time | save | 20 mins/use |
| leverage.author.code.block | save | 6 blocks/use |
| leverage.author.code.path | save | 7 paths/use |
| leverage.author.khue | save | 9 khues/use |
| leverage.support.time | save | 30 mins/fail |
| leverage.support.signal | gain | 1 signal/use |
| leverage.support.defence | gain | 3 defences/use |
| leverage.adopt.freq | — | 5 uses/week |
| leverage.adopt.time | cost | 45 mins/tool |


### 3.2. dynamodb-dao-generator

| metric | polarity | value |
|--------|----------|-------|
| leverage.author.time | save | 360 mins/use |
| leverage.author.code.block | save | 35 blocks/use |
| leverage.author.code.path | save | 40 paths/use |
| leverage.author.khue | save | 25 khues/use |
| leverage.support.time | save | 120 mins/fail |
| leverage.support.signal | gain | 4 signals/use |
| leverage.support.defence | gain | 8 defences/use |
| leverage.adopt.freq | — | 0.5 uses/week |
| leverage.adopt.time | cost | 180 mins/tool |


### 3.3. declapract-typescript-ehmpathy

| metric | polarity | value |
|--------|----------|-------|
| leverage.author.time | save | 360 mins/use |
| leverage.author.code.block | save | 75 blocks/use |
| leverage.author.code.path | save | 0 paths/use |
| leverage.author.khue | save | 80 khues/use |
| leverage.support.time | save | 60 mins/fail |
| leverage.support.signal | gain | 5 signals/use |
| leverage.support.defence | gain | 43 defences/use |
| leverage.adopt.freq | — | 0.25 uses/week |
| leverage.adopt.time | cost | 90 mins/tool |


---


## 4. composition options for leverage.author

### 4.1. option A: gut-only

use only the direct time estimate:

```
leverage.author = leverage.author.time
```

**rationale:** the estimator already considered blocks, paths, and khues implicitly when estimating time.

**risk:** gut estimates may be biased or inconsistent across tools.


### 4.2. option B: decomposed-only

convert granular metrics to time, ignore gut estimate:

```
leverage.author =
  (leverage.author.code.block × mins/block) +
  (leverage.author.code.path × mins/path) +
  (leverage.author.khue × mins/khue)

where:
  mins/block = 5 mins
  mins/path = 3 mins
  mins/khue = 5 mins
```

**rationale:** decomposed estimates are more auditable and consistent.

**risk:** rate assumptions (mins/block, etc.) may be wrong.


### 4.3. option C: averaged (gut + decomposed) / 2

```
time.gut = leverage.author.time
time.decomposed = (blocks × 5) + (paths × 3) + (khues × 5)
leverage.author = (time.gut + time.decomposed) / 2
```

**rationale:** balances intuition with structured breakdown. errors in either method are dampened.

**risk:** if gut and decomposed diverge significantly, the average may not represent either well.


### 4.4. option D: weighted blend

```
leverage.author = (α × time.gut) + ((1-α) × time.decomposed)

where α = 0.3 (favor decomposed)
```

**rationale:** allows tuning trust between methods.


---


## 5. applying option A/B/C to tools

### 5.1. time calculations

| tool | time.gut | time.decomposed | option C (avg) |
|------|----------|-----------------|----------------|
| with-simple-cache | 20 mins | (6×5)+(7×3)+(9×5) = 30+21+45 = **96 mins** | (20+96)/2 = **58 mins** |
| dynamodb-dao-gen | 360 mins | (35×5)+(40×3)+(25×5) = 175+120+125 = **420 mins** | (360+420)/2 = **390 mins** |
| declapract-ts | 360 mins | (75×5)+(0×3)+(80×5) = 375+0+400 = **775 mins** | (360+775)/2 = **568 mins** |


### 5.2. rankings by option

| rank | option A (gut) | option B (decomposed) | option C (averaged) |
|------|----------------|----------------------|---------------------|
| 1 | dynamodb = declapract (360) | declapract (775) | declapract (568) |
| 2 | dynamodb = declapract (360) | dynamodb (420) | dynamodb (390) |
| 3 | with-simple-cache (20) | with-simple-cache (96) | with-simple-cache (58) |

**observation:**
- option A shows dynamodb = declapract (tie)
- option B and C differentiate: declapract > dynamodb
- decomposed method reveals that declapract's high khue count (80) provides significant leverage


---


## 6. incorporating leverage.support

### 6.1. the challenge

leverage.support metrics have different scopes:
- leverage.support.time is per-fail (not per-use)
- leverage.support.signal and leverage.support.defence are per-use

how do we combine them with leverage.author?


### 6.2. option S1: ignore support (author-only)

```
leverage.composite = leverage.author × freq
```

**rationale:** support benefits are hard to quantify and compare.

**risk:** undervalues tools with strong operational benefits.


### 6.3. option S2: separate support score

don't combine; report two scores:

```
leverage.author.composite = leverage.author × freq
leverage.support.composite = (signals + defences) × freq
```

**rationale:** different stakeholders care about different things.


### 6.4. option S3: convert support to time-equivalent

```
leverage.support.time.equivalent =
  leverage.support.time × fail.rate +
  (signals × mins/signal × use.rate) +
  (defences × mins/defence × use.rate)

where:
  fail.rate = estimated failures per week (e.g., 0.1)
  mins/signal = 2 mins (time saved by having observability)
  mins/defence = 5 mins (time saved by not having to handle edge case)
```

**rationale:** converts everything to time, enabling direct comparison.

**risk:** requires additional estimates (fail.rate, mins/signal, mins/defence).


### 6.5. option S4: weighted lifecycle blend

```
leverage.composite =
  (w.author × leverage.author.time) +
  (w.support × leverage.support.time)

where:
  w.author = 1.0
  w.support = 1.0  (default: equal weight)
```

**rationale:** explicitly weights development vs operations.

**note:** if both are converted to time-equivalent (via S3), then S4 with w.author = w.support = 1.0 is equivalent to S3. the weights become a policy choice: "is 1 minute saved authoring worth more/less than 1 minute saved debugging?"


---


## 7. symmetric treatment of author and support

### 7.1. the insight

leverage.author and leverage.support are symmetric — both have:
- a **time** estimate (gut feeling)
- **sub-dimensions** that decompose into time

but they have *different* sub-dimensions:

| lifecycle | time metric | sub-dimensions |
|-----------|-------------|----------------|
| **author** | leverage.author.time | blocks, paths, khues |
| **support** | leverage.support.time | signals, defences |

the symmetric treatment: compose each using its own sub-dimensions.


### 7.2. leverage.author composition (from section 4)

```
author.time.decomposed = (blocks × 5) + (paths × 3) + (khues × 5)
leverage.author/use = (α × time.gut) + ((1-α) × time.decomposed)
leverage.author/week = leverage.author/use × freq
```


### 7.3. leverage.support composition

```
support.time.decomposed = (signals × mins/signal) + (defences × mins/defence)

where:
  mins/signal = 10 mins (time saved by having observability during incident)
  mins/defence = 15 mins (time saved by not having to handle edge case)

leverage.support.time/fail = (α × time.gut) + ((1-α) × time.decomposed)
leverage.support/week = leverage.support.time/fail × fail.rate
```

**note:** signals and defences decompose support.time the same way blocks/paths/khues decompose author.time.


---


## 8. applying composition to tools

### 8.1. leverage.author/use calculations (α=0.5)

| tool | time.gut | blocks×5 | paths×3 | khues×5 | time.decomposed | author/use |
|------|----------|----------|---------|---------|-----------------|------------|
| with-simple-cache | 20 | 30 | 21 | 45 | 96 | (0.5×20)+(0.5×96) = **58 mins** |
| dynamodb-dao-gen | 360 | 175 | 120 | 125 | 420 | (0.5×360)+(0.5×420) = **390 mins** |
| declapract-ts | 360 | 375 | 0 | 400 | 775 | (0.5×360)+(0.5×775) = **568 mins** |


### 8.2. leverage.support.time/fail calculations (α=0.5)

| tool | time.gut | signals×10 | defences×15 | time.decomposed | time/fail |
|------|----------|------------|-------------|-----------------|-----------|
| with-simple-cache | 30 | 1×10=10 | 3×15=45 | 55 | (0.5×30)+(0.5×55) = **43 mins** |
| dynamodb-dao-gen | 120 | 4×10=40 | 8×15=120 | 160 | (0.5×120)+(0.5×160) = **140 mins** |
| declapract-ts | 60 | 5×10=50 | 43×15=645 | 695 | (0.5×60)+(0.5×695) = **378 mins** |

**observation:** declapract-ts has highest support.time/fail due to 43 defences — each defence saves debugging time when failures occur.


### 8.3. weekly totals

```
leverage.author/week = leverage.author/use × freq
leverage.support/week = leverage.support.time/fail × fail.rate
```

| tool | author/use | freq | author/week | time/fail | fail.rate | support/week |
|------|------------|------|-------------|-----------|-----------|--------------|
| with-simple-cache | 58 | 5 | **290 mins** | 43 | 0.1 | **4.3 mins** |
| dynamodb-dao-gen | 390 | 0.5 | **195 mins** | 140 | 0.1 | **14 mins** |
| declapract-ts | 568 | 0.25 | **142 mins** | 378 | 0.1 | **38 mins** |

**observation:** support/week is much smaller than author/week because fail.rate (0.1) << freq. support matters most when fail.rate is high or when w.support weight is increased.


---


## 9. composite leverage calculation

### 9.1. the composite formula

```
leverage.composite/week =
  (w.author × leverage.author/week) +
  (w.support × leverage.support/week) -
  (leverage.adopt.time / amortization.weeks)

where:
  leverage.author/week = leverage.author/use × freq
  leverage.support/week = leverage.support/fail × fail.rate

  w.author = 1.0 (default)
  w.support = 1.0 (default)
  amortization.weeks = 52
```


### 9.2. calculations (α=0.5, w.author=1.0, w.support=1.0)

| tool | author/week | support/week | adopt.amortized | composite/week |
|------|-------------|--------------|-----------------|----------------|
| with-simple-cache | 290 | 4.3 | 45/52=0.9 | (1.0×290)+(1.0×4.3)-0.9 = **293 mins** |
| dynamodb-dao-gen | 195 | 14 | 180/52=3.5 | (1.0×195)+(1.0×14)-3.5 = **206 mins** |
| declapract-ts | 142 | 38 | 90/52=1.7 | (1.0×142)+(1.0×38)-1.7 = **178 mins** |


### 9.3. final ranking (composite/week, default weights)

| rank | tool | composite/week | hrs/week |
|------|------|----------------|----------|
| 1 | **with-simple-cache** | 293 mins | 4.9 hrs |
| 2 | dynamodb-dao-generator | 206 mins | 3.4 hrs |
| 3 | declapract-typescript-ehmpathy | 178 mins | 3.0 hrs |


---


## 10. sensitivity analysis: how weights affect ranking

### 10.1. varying α (gut vs decomposed) with w.support=1.0

| α | interpretation | cache | dynamodb | declapract |
|---|----------------|-------|----------|------------|
| 1.0 | gut only | 104 (#2) | 194 (#1) | 96 (#3) |
| 0.5 | balanced | 293 (#1) | 206 (#2) | 178 (#3) |
| 0.0 | decomposed only | 484 (#1) | 224 (#2) | 232 (#3) |

**insight:** α=1.0 (gut only) is the only config that ranks dynamodb #1.


### 10.2. varying w.support (with α=0.5)

| w.support | cache | dynamodb | declapract | notes |
|-----------|-------|----------|------------|-------|
| 0.0 | 289 (#1) | 192 (#2) | 140 (#3) | author only |
| 1.0 | 293 (#1) | 206 (#2) | 178 (#3) | balanced |
| 5.0 | 311 (#1) | 262 (#2) | 330 (#3→#2) | support-heavy |
| 10.0 | 332 (#2) | 332 (#2) | 520 (#1) | support-dominant |

**insight:** declapract only overtakes others when w.support ≥ 10 (support dominates), due to its 43 defences.


---


## 11. ranking stability matrix

| weights | #1 | #2 | #3 |
|---------|----|----|---|
| α=1.0, w.support=0.0 | dynamodb | cache | declapract |
| α=0.5, w.support=0.0 | cache | dynamodb | declapract |
| α=0.5, w.support=1.0 | cache | dynamodb | declapract |
| α=0.5, w.support=10.0 | declapract | cache | dynamodb |

**key insights:**
- cache ranks #1 in most configurations due to high freq (5/week)
- dynamodb only ranks #1 when α=1.0 (trust gut only)
- declapract only ranks #1 when w.support ≥ 10 (support dominates), due to 43 defences
- low freq (0.25/week) penalizes declapract unless support is heavily weighted


---


## 12. recommendations

### 12.1. use configurable α for gut vs decomposed weighting

```
leverage.X/scope = (α × time.gut) + ((1-α) × time.decomposed)
```

- α = 0.5 balances intuition with systematic breakdown
- α = 0.0 for maximum auditability (trust decomposed only)
- α = 1.0 when estimator has high domain expertise (trust gut)
- divergence between gut and decomposed (>2x) signals need for review

### 12.2. use configurable w.author / w.support for lifecycle weighting

```
leverage.composite/week = (w.author × author/week) + (w.support × support/week)
```

- default w.author = w.support = 1.0 (equal lifecycle weight)
- increase w.support for operationally-critical systems
- decrease w.support for greenfield/throwaway projects

### 12.3. include adoption cost amortization

```
leverage.adopt.time / 52 weeks
```

- spreads one-time cost over expected tool lifetime
- prevents high adoption cost from unfairly penalizing high-leverage tools


---


## 13. final composite formula

```
# leverage.author (symmetric)
author.time.decomposed = (blocks × 5) + (paths × 3) + (khues × 5)
leverage.author/use = (α × time.gut) + ((1-α) × author.time.decomposed)
leverage.author/week = leverage.author/use × freq

# leverage.support (symmetric)
support.time.decomposed = (signals × 10) + (defences × 15)
leverage.support/fail = (α × time.gut) + ((1-α) × support.time.decomposed)
leverage.support/week = leverage.support/fail × fail.rate

# leverage.composite
leverage.composite/week =
  (w.author × leverage.author/week) +
  (w.support × leverage.support/week) -
  (leverage.adopt.time / 52)

# default weights
α = 0.5
w.author = 1.0
w.support = 1.0
fail.rate = 0.1
```


---


## 14. open questions

1. what are appropriate values for mins/block, mins/path, mins/khue?
2. what is a reasonable fail.rate assumption?
3. should mins/signal and mins/defence vary by tool or context?
4. should amortization period be shorter than 52 weeks for fast-evolving tools?
5. how to handle tools where gut and decomposed diverge by >2x?

