# domain research: leverage dimensions (v4)

this document researches additional dimensions of leverage that may have been missed in v1, v2, and v3 research. it catalogs dimensions from 21+ sources and clusters unique dimensions.


---


## 1. citation index

| # | source | url |
|---|--------|-----|
| 1 | DX - Developer Productivity Guide | https://getdx.com/blog/developer-productivity/ |
| 2 | Bain & Company - Beyond Code Generation | https://www.bain.com/insights/beyond-code-generation-more-efficient-software-development-tech-report-2024/ |
| 3 | McKinsey - Developer Productivity | https://www.mckinsey.com/industries/technology-media-and-telecommunications/our-insights/yes-you-can-measure-software-developer-productivity |
| 4 | Addy Osmani - High Leverage Activities | https://addyosmani.com/blog/high-leverage-activites/ |
| 5 | Bill de hÓra - Leverage in Engineering | https://dehora.net/journal/leverage-in-engineering-organisations |
| 6 | DX - DORA Metrics Guide | https://getdx.com/blog/dora-metrics/ |
| 7 | Multitudes - DORA and SPACE | https://www.multitudes.com/blog/dora-and-space-metrics |
| 8 | DX - SPACE Framework | https://getdx.com/blog/space-metrics/ |
| 9 | Pragmatic Engineer - Developer Productivity Framework | https://newsletter.pragmaticengineer.com/p/developer-productivity-a-new-framework |
| 10 | LinkedIn Engineering - Building a Platform for Leverage | https://engineering.linkedin.com/blog/2020/building-a-platform-for-leverage |
| 11 | LinearB - AI as Value Multiplier | https://linearb.io/blog/ai-as-value-multiplier-human-centric-leadership |
| 12 | Codacy - ISO/IEC 25010 Software Quality Model | https://blog.codacy.com/iso-25010-software-quality-model |
| 13 | ISO 25000 - ISO 25010 Standard | https://iso25000.com/en/iso-25000-standards/iso-25010 |
| 14 | Perforce - What is ISO 25010 | https://www.perforce.com/blog/qac/what-is-iso-25010 |
| 15 | Opsera - 13 Code Quality Metrics | https://opsera.ai/blog/13-code-quality-metrics-that-you-must-track/ |
| 16 | BrowserStack - Top 15 Code Quality Metrics | https://www.browserstack.com/guide/software-code-quality-metrics |
| 17 | ACM Queue - DevEx: What Actually Drives Productivity | https://queue.acm.org/detail.cfm?id=3595878 |
| 18 | InfoQ - DevEx Metrics Framework | https://www.infoq.com/articles/devex-metrics-framework/ |
| 19 | Wikipedia - List of System Quality Attributes | https://en.wikipedia.org/wiki/List_of_system_quality_attributes |
| 20 | O'Reilly - Extensibility and Flexibility | https://www.oreilly.com/library/view/software-architects-handbook/9781788624060/5f51da99-e0fe-4fed-8e4f-4b0aa361a31c.xhtml |
| 21 | Port.io - Developer Self-Service | https://www.port.io/glossary/developer-self-service |
| 22 | Google Cloud - Golden Paths | https://cloud.google.com/blog/products/application-development/golden-paths-for-engineering-execution-consistency |
| 23 | SEI CMU - System Resilience | https://insights.sei.cmu.edu/blog/system-resilience-part-2-how-system-resilience-relates-to-other-quality-attributes/ |
| 24 | The Coder Cafe - Resilient vs Fault-tolerant | https://read.thecoder.cafe/p/resilient-fault-tolerant-robust-reliable |
| 25 | GeeksforGeeks - Latency in System Design | https://www.geeksforgeeks.org/system-design/latency-in-system-design/ |
| 26 | Zuplo - API Documentation for Onboarding | https://zuplo.com/learning-center/leverage-api-documentation-for-faster-onboarding |
| 27 | MuleSoft - API Discoverability | https://blogs.mulesoft.com/dev-guides/api-design/developer-experience-with-api-discoverability/ |
| 28 | Coralogix - System Traceability | https://coralogix.com/blog/system-traceability-what-is-it-and-how-can-you-implement-it/ |
| 29 | GitHub Gist - Idempotency, Determinism, Pure Functions | https://gist.github.com/nouex/c8e5bd4dc8293ea9809dac92f1a07b0a |
| 30 | Hexlet - Pure Functions and Side Effects | https://hexlet.io/courses/intro_to_programming/lessons/pure/theory_unit |
| 31 | Microsoft Playbook - Internationalization | https://microsoft.github.io/code-with-engineering-playbook/non-functional-requirements/internationalization/ |
| 32 | Wikipedia - Formal Verification | https://en.wikipedia.org/wiki/Formal_verification |
| 33 | Galois - What Are Formal Methods | https://www.galois.com/what-are-formal-methods |
| 34 | Ambassador - Maximize Developer Velocity | https://www.getambassador.io/blog/boost-developer-velocity-optimizing-feedback-loops |
| 35 | The New Stack - Optimize Inner Dev Loop | https://thenewstack.io/optimize-your-inner-dev-loop-to-increase-developer-velocity/ |
| 36 | FinOps Foundation - Optimize Cloud Usage | https://www.finops.org/framework/domains/optimize-usage-cost/ |
| 37 | McKinsey - FinOps as Code | https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/everything-is-better-as-code-using-finops-to-manage-cloud-costs |
| 38 | Martin Fowler - Feature Toggles | https://martinfowler.com/articles/feature-toggles.html |
| 39 | LaunchDarkly - Feature Flags 101 | https://launchdarkly.com/blog/what-are-feature-flags/ |


---


## 2. dimensions catalogued by source


### 2.1. productivity frameworks

**[1] DX - Developer Productivity Guide:**
> "The Developer Experience Index is often the highest-leverage metric because it correlates strongly with all other productivity outcomes."

> "Each one-point improvement in DXI saves 13 minutes per developer per week. For a team of 100 developers, that's over 1,000 hours annually."

dimensions identified: **developer experience**, **time savings**


**[2] Bain & Company - Beyond Code Generation:**
> "In practice, engineering organizations using such tools are seeing efficiency improvements of about 10% to 15% on average."

> "Organizations that take a more comprehensive approach can see efficiency gains of 30% or more. The extra gains result from going beyond generative AI code generation and taking a more comprehensive approach to improving efficiency."

dimensions identified: **efficiency**, **comprehensiveness**


**[3] McKinsey - Developer Productivity:**
> "Complementing DORA and SPACE metrics with opportunity-focused metrics can create an end-to-end view of software developer productivity."

dimensions identified: **opportunity focus**, **end-to-end visibility**


**[4] Addy Osmani - High Leverage Activities:**
> "Leverage = impact produced / time invested. It is the ability to get more done with less effort, time or money."

> "If you improve your personal effectiveness, maybe you can make things 10% better. If you improve the effectiveness of an organization of 30 people by 10%, that's effectively 3 software engineers."

> "A valuable activity is identifying and creating ways and means to increase leverage. The term 'force multiplier' is a complementary idea—a force multiplier is something that gives us increased leverage."

dimensions identified: **impact/time ratio**, **organizational effectiveness**, **force multiplication**


**[5] Bill de hÓra - Leverage in Engineering:**
> "If you improve the effectiveness of an organization of 30 people by 10%, that's effectively 3 software engineers."

dimensions identified: **organizational leverage**, **team multiplier**


### 2.2. DORA and SPACE metrics

**[6] DX - DORA Metrics Guide:**
> "The four key DORA metrics are: Deployment Frequency, Lead Time for Changes, Mean Time to Recovery, Change Failure Rate."

> "A key insight from DORA research is that high-performing teams excel across all four metrics simultaneously—they don't sacrifice stability for speed or vice versa."

dimensions identified: **deployment frequency**, **lead time**, **recovery time**, **change failure rate**, **stability**


**[7] Multitudes - DORA and SPACE:**
> "While DORA focuses on outcomes and impact, SPACE considers effort, output, and human factors."

> "DORA can identify *what* is happening in the delivery process (e.g., a high change failure rate), while SPACE can illuminate *why* it is occurring (e.g., issues in communication, burnout, or workflow interruptions)."

dimensions identified: **outcomes/impact**, **effort**, **human factors**, **communication**, **burnout prevention**


**[8] DX - SPACE Framework:**
> "SPACE metrics (satisfaction and well-being, performance, activity, communication and collaboration, and efficiency and flow) were developed by GitHub and Microsoft Research."

> "Teams have been shown to improve productivity by 20-30% when they measure across all five SPACE dimensions rather than focusing solely on activity metrics."

dimensions identified: **satisfaction**, **well-being**, **performance**, **activity**, **communication**, **collaboration**, **efficiency**, **flow**


### 2.3. platform engineering

**[10] LinkedIn Engineering - Building a Platform for Leverage:**
> "One of LinkedIn's core engineering principles is to create leverage. In practice, this means building software that is easy to reuse by other teams by favoring platforms that generalize long-term functionality rather than building inflexible, single-purpose software."

dimensions identified: **reusability**, **generalization**, **platform thinking**


**[11] LinearB - AI as Value Multiplier:**
> "The focus should be on maximizing the 'value generation leverage' of each engineer, reframing developers from cost centers to creators of capital assets that generate revenue. The goal becomes amplifying the value each developer can create."

dimensions identified: **value generation**, **capital asset creation**, **revenue generation**


### 2.4. ISO 25010 quality model

**[12] Codacy - ISO/IEC 25010:**
> "ISO/IEC 25010 organizes software quality into two dimensions: product quality and quality in use."

> "Product quality refers to the inherent characteristics of the software product itself. It encompasses functionality, reliability, usability, efficiency, maintainability, and portability."

dimensions identified: **product quality**, **quality in use**


**[13] ISO 25000 - ISO 25010:**
> "ISO 25010 is the international model that defines eight quality characteristics—functional suitability, performance efficiency, compatibility, usability, reliability, security, maintainability, and portability—used to evaluate and improve software products."

dimensions identified:
1. **functional suitability**
2. **performance efficiency**
3. **compatibility**
4. **usability**
5. **reliability**
6. **security**
7. **maintainability**
8. **portability**


**[14] Perforce - What is ISO 25010:**
> "Maintainability refers to how well a product or system can be modified to improve, correct, or adapt to changes. Its sub-characteristics include: Modularity, Reusability, Analysability, Modifiability, Testability."

> "Quality in use: Effectiveness, Efficiency, Satisfaction, Freedom from Risk, Context Coverage."

dimensions identified: **modularity**, **analysability**, **modifiability**, **testability**, **effectiveness**, **freedom from risk**, **context coverage**


### 2.5. code quality metrics

**[15] Opsera - 13 Code Quality Metrics:**
> "Code quality metrics indicate how reliable, maintainable, and efficient your codebase is. They help teams spot bugs early, reduce technical debt, and improve overall development speed."

> "These metrics cover a wide range of factors, including code complexity, maintainability, readability, test coverage, defect rates, reusability, and performance."

dimensions identified: **code complexity**, **test coverage**, **defect rates**


**[16] BrowserStack - Code Quality Metrics:**
> "Modularity evaluates the degree to which code is organized into discrete, independent modules. High modularity supports reuse by enabling developers to use individual modules across different projects without modification."

> "Testability refers to how easily code can be validated through testing. Testable code is modular, predictable, and free from unnecessary dependencies."

> "Reusability measures whether existing assets — such as code — can be used again. Assets are more easily reused if they have characteristics such as modularity or loose coupling. Reusability can be measured by the number of interdependencies."

dimensions identified: **modularity**, **testability**, **loose coupling**, **interdependencies**


### 2.6. DevEx framework

**[17] ACM Queue - DevEx:**
> "The DevEx framework distills developer experience to its three core dimensions: feedback loops, cognitive load, and flow state."

> "These dimensions emerged from real-world application of prior research, which identified 25 sociotechnical factors affecting DevEx."

dimensions identified: **feedback loops**, **cognitive load**, **flow state**


**[18] InfoQ - DevEx Metrics Framework:**
> "Feedback loops refer to the speed and quality of responses relative to actions performed. Fast feedback loops are a critical component of efficient development processes."

> "Cognitive load encompasses the amount of mental processing required for a developer to perform a task. High cognitive load can result from challenges like poorly documented code or systems."

> "Flow state refers to the mental state of being fully absorbed and energized while engaged in an activity, characterized by intense focus and enjoyment."

dimensions identified: **feedback speed**, **feedback quality**, **mental processing load**, **focus**, **enjoyment**


### 2.7. system quality attributes

**[19] Wikipedia - System Quality Attributes:**
> "Within systems engineering, quality attributes are realized non-functional requirements used to evaluate the performance of a system. These are sometimes named architecture characteristics, or 'ilities' after the suffix many of the words share."

> "The changeability of a software system is the ease with which it can be modified to match changes in the requirements or the environment. Changeability includes the non-functional requirements for adaptability, flexibility, modifiability and robustness."

dimensions identified: **changeability**, **adaptability**, **flexibility**, **robustness**


**[20] O'Reilly - Extensibility and Flexibility:**
> "Flexibility lets software adapt to different use cases without modification. Extensibility lets you add new capabilities that weren't originally built in."

> "Adaptability allows systems to respond to new challenges—technical, organizational, or user-driven."

> "Scalability means the system can accommodate growth in usage without compromising performance or stability."

> "Composability assembles complex systems from independent, interchangeable components. Extensibility makes those components grow beyond their original scope."

dimensions identified: **extensibility**, **scalability**, **composability**


### 2.8. developer autonomy

**[21] Port.io - Developer Self-Service:**
> "Developer self-service is a platform engineering practice that allows developers to independently access, manage and deploy the resources and tools they need. By empowering developers to act autonomously, without the direct support of DevOps or IT, self-service minimizes development bottlenecks, improves efficiency, accelerates the pace of development and empowers developers."

dimensions identified: **autonomy**, **self-service**, **independence**


**[22] Google Cloud - Golden Paths:**
> "A golden path is a recommended, standardized way for developers to complete common tasks like spinning up services, configuring CI/CD, or deploying to production. It bundles together the templates, tooling, configurations, and best practices your team has already vetted."

> "Golden paths enable developers to accomplish tasks independently while ensuring platform engineers and DevOps have embedded the organization's standards."

dimensions identified: **standardization**, **best practice embedding**, **guardrails**


### 2.9. resilience and fault tolerance

**[23] SEI CMU - System Resilience:**
> "Basically, a system is resilient if it continues to carry out its mission in the face of adversity (i.e., if it provides required capabilities despite excessive stresses that can cause disruptions)."

> "System resilience is not an isolated quality attribute—it is directly related to robustness, safety, cybersecurity, anti-tamper, survivability, capacity, longevity, and interoperability."

dimensions identified: **resilience**, **survivability**, **longevity**, **interoperability**


**[24] The Coder Cafe - Resilient vs Fault-tolerant:**
> "Fault tolerance specifically refers to a system's capability to handle faults without any degradation or downtime. In the event of an error, end-users remain unaware of any issues."

> "Robustness highlights a system's ability to withstand external stressors. Graceful degradation is an illustration of robustness."

> "A system that experiences errors with some interruption in service or graceful degradation of performance is termed 'resilient'. In resilience, the system adapts to the error."

dimensions identified: **fault tolerance**, **graceful degradation**, **error adaptation**


### 2.10. performance efficiency

**[25] GeeksforGeeks - Latency in System Design:**
> "Latency is the time it takes for a request to be processed and a response to be returned. High latency can lead to slow performance, while low latency can result in faster and more responsive systems."

> "Throughput refers to the number of requests a system can handle at the same time."

> "In most systems, there is a trade-off between latency and throughput."

dimensions identified: **latency**, **throughput**, **responsiveness**


### 2.11. documentation and discoverability

**[26] Zuplo - API Documentation for Onboarding:**
> "Postman's research found 52% of developers identify poor documentation as their biggest obstacle when working with APIs."

> "Effective API docs can cut onboarding time from weeks to hours and determine whether developers adopt your API or flee to competitors."

dimensions identified: **documentation quality**, **onboarding speed**, **adoption rate**


**[27] MuleSoft - API Discoverability:**
> "Even perfect documentation fails if developers can't find what they need when they need it. Discoverability transforms good documentation into genuinely useful documentation."

dimensions identified: **discoverability**, **findability**


### 2.12. observability

**[28] Coralogix - System Traceability:**
> "The three pillars of observability are Metrics, Tracing, and Logging. Each pillar has a distinct role in gaining visibility into containerized or serverless applications."

> "Distributed tracing is a critical component of observability in connected systems and focuses on performance monitoring and troubleshooting."

> "Centralizing logs in a microservices environment improves debuggability and traceability across multiple services."

dimensions identified: **metrics**, **tracing**, **logging**, **debuggability**, **traceability**


### 2.13. predictability and determinism

**[29] GitHub Gist - Idempotency, Determinism, Pure Functions:**
> "A deterministic function will always return the same result for the same set of inputs, making it predictable and easy to test."

> "Idempotent functions can safely be run multiple times. For example, an idempotent function that inserts records into a table is one that would avoid creating duplicate records even if you run it repeatedly."

dimensions identified: **determinism**, **idempotency**, **predictability**


**[30] Hexlet - Pure Functions:**
> "A pure function is a function that is deterministic and doesn't produce side effects."

> "Improvements from pure functions include: Predictability, Maintainability, Composability, Testability."

> "Everything about pure functions screams 'easier': they are easier to read, easier to debug, easier to test."

dimensions identified: **purity**, **side-effect freedom**, **parallelizability**


### 2.14. internationalization

**[31] Microsoft Playbook - Internationalization:**
> "Internationalization (i18n) and Localization (l10n) refer to the design and adaptation of software systems to support multiple languages, cultures, and regions."

> "Key practices include: Text Externalization, Unicode Support, Date and Time Formatting, Number and Currency Formatting, Locale-Sensitive Data Processing, Bidirectional Text Support."

dimensions identified: **internationalization (i18n)**, **localization (l10n)**, **cultural adaptability**


### 2.15. formal verification

**[32] Wikipedia - Formal Verification:**
> "Formal Verification is a promising method to provide security guarantees by mathematically ascertaining the correctness of designs."

> "Validation seeks to examine the correctness in the operation by examining its behavior (e.g., through simulation). Verification seeks to examine the correctness by a mathematical proof."

dimensions identified: **verifiability**, **provable correctness**


**[33] Galois - Formal Methods:**
> "Formal Methods are a set of mathematically rigorous techniques used to specify, write, analyze, and verify software systems. They go beyond traditional testing by using logic-based reasoning to prove that a system behaves correctly under all possible conditions."

> "One advantage of formal methods is its soundness guarantee. This ensures that no error goes undetected (zero false negatives)."

dimensions identified: **soundness**, **exhaustiveness**, **formal specification**


### 2.16. developer velocity

**[34] Ambassador - Developer Velocity:**
> "The faster the feedback loop, the faster developers can refactor and test again."

dimensions identified: **feedback loop speed**, **iteration rate**


**[35] The New Stack - Inner Dev Loop:**
> "The inner loop consists of local coding, building, running, and testing the application—all activities that you, as a developer, can control."

> "In a traditional inner dev loop, if a typical developer codes for 360 minutes (6 hours) a day, with a traditional local iterative development loop of 5 minutes, they can expect to make ~70 iterations of their code per day."

> "If a developer codes for six hours per day, we move from 70 to 40 iterations by moving to containers. Throughout a two-week sprint, this is 300 missing cycles."

dimensions identified: **inner loop speed**, **iteration count**, **local development speed**


### 2.17. cost efficiency

**[36] FinOps Foundation - Optimize Cloud Usage:**
> "Usage optimization is the process of ensuring a close match between the cloud resources provisioned and the needs of the business."

> "Engineering and operations team members work with product management to maintain product budgets by considering the efficient design and use of resources via activities like rightsizing."

dimensions identified: **resource utilization**, **rightsizing**, **cost optimization**


**[37] McKinsey - FinOps as Code:**
> "More than 80% of respondents point to managing cloud spend as their top organizational challenge, and these same respondents estimate that nearly 1/3 of their cloud spend is inefficient or wasted."

> "FaC (FinOps as Code) can be used to enforce budgets and cost-efficient architecture practices, automatically identify areas of cost reduction."

dimensions identified: **spend efficiency**, **waste reduction**, **budget enforcement**


### 2.18. configurability

**[38] Martin Fowler - Feature Toggles:**
> "The term feature flag (or toggle) is used very broadly for many different concepts. They are popular for controlling code paths in operation (A/B testing, canary releases, rollouts and rollbacks) and for hiding incomplete implementations while committing to head."

dimensions identified: **feature toggleability**, **runtime control**, **rollout control**


**[39] LaunchDarkly - Feature Flags 101:**
> "Feature flags (also known as feature toggles or feature switches) are a software development and product experimentation technique that controls functionality during runtime, without deploying new code."

> "Feature flags determine at runtime which portions of code are executed."

dimensions identified: **runtime configurability**, **deployment independence**


---


## 3. dimension clustering

based on the 39 sources, here are the unique dimensions clustered by category:


### 3.1. dimensions already in v1/v2/v3

| dimension | v1/v2/v3 term | confirmed by sources |
|-----------|---------------|---------------------|
| speed/time | leverage.faster | [1], [4], [6], [25], [34], [35] |
| cognitive simplicity | leverage.simpler | [17], [18] |
| safety/risk | leverage.safer | [13], [23], [24] |
| observability | leverage.observable | [28] |
| readability | leverage.readable | [15], [30] |
| composability | leverage.composable | [20], [30] |
| reusability | leverage.reusable | [10], [14], [16] |
| evolvability | leverage.evolvable | [14], [19], [20] |


### 3.2. potentially missing dimensions

| candidate dimension | definition | sources | leverage formula |
|--------------------|------------|---------|------------------|
| **leverage.testable** | effort to validate correctness | [14], [16], [30] | test_effort_wout / test_effort_with |
| **leverage.portable** | effort to run on different platforms | [13], [31] | port_effort_wout / port_effort_with |
| **leverage.resilient** | effort to recover from failures | [23], [24] | recovery_effort_wout / recovery_effort_with |
| **leverage.discoverable** | effort to find what you need | [26], [27] | find_effort_wout / find_effort_with |
| **leverage.autonomous** | effort to self-serve wout waiting | [21], [22] | wait_time_wout / wait_time_with |
| **leverage.predictable** | effort to anticipate behavior | [29], [30] | predict_effort_wout / predict_effort_with |
| **leverage.traceable** | effort to trace causality | [28] | trace_effort_wout / trace_effort_with |
| **leverage.verifiable** | effort to prove correctness | [32], [33] | verify_effort_wout / verify_effort_with |
| **leverage.configurable** | effort to change behavior wout code | [38], [39] | config_effort_wout / config_effort_with |
| **leverage.scalable** | effort to handle growth | [20] | scale_effort_wout / scale_effort_with |
| **leverage.efficient** | resources consumed per outcome | [25], [36], [37] | resources_wout / resources_with |
| **leverage.compatible** | effort to integrate with others | [13] | compat_effort_wout / compat_effort_with |
| **leverage.secure** | effort to maintain security | [13], [23] | security_effort_wout / security_effort_with |
| **leverage.accessible** | effort for all users to use | [31] | access_effort_wout / access_effort_with |


### 3.3. dimension taxonomy

```
leverage dimensions (expanded)
├── time dimensions
│   ├── leverage.faster (execution time)
│   ├── leverage.responsive (latency)
│   └── leverage.scalable (growth handling)
│
├── cognitive dimensions
│   ├── leverage.simpler (thought cycles)
│   ├── leverage.readable (comprehension)
│   ├── leverage.discoverable (findability)
│   └── leverage.predictable (anticipation)
│
├── quality dimensions
│   ├── leverage.safer (risk reduction)
│   ├── leverage.testable (validation ease)
│   ├── leverage.verifiable (proof ease)
│   └── leverage.secure (attack resistance)
│
├── operational dimensions
│   ├── leverage.observable (visibility)
│   ├── leverage.traceable (causality tracking)
│   ├── leverage.resilient (failure recovery)
│   └── leverage.configurable (runtime control)
│
├── structural dimensions
│   ├── leverage.composable (integration ease)
│   ├── leverage.reusable (multi-use potential)
│   ├── leverage.evolvable (change ease)
│   ├── leverage.portable (platform independence)
│   └── leverage.compatible (interoperability)
│
├── developer dimensions
│   ├── leverage.autonomous (self-service)
│   └── leverage.accessible (universal usability)
│
└── resource dimensions
    └── leverage.efficient (resource optimization)
```


---


## 4. analysis: which dimensions to add?

### 4.1. high-confidence additions

these dimensions are well-supported by multiple sources and fill clear gaps:

| dimension | rationale | arm.effort | arm.load |
|-----------|-----------|------------|----------|
| **leverage.testable** | distinct from safety; about validation ease | test scenarios covered | test setup complexity |
| **leverage.discoverable** | distinct from readable; about findability | content indexed | search effort |
| **leverage.autonomous** | captures self-service leverage | actions self-serviceable | approval/wait friction |
| **leverage.predictable** | captures determinism benefit | behavior states covered | surprises possible |


### 4.2. medium-confidence additions

these dimensions are valid but may overlap with existing ones:

| dimension | overlaps with | distinction |
|-----------|---------------|-------------|
| **leverage.resilient** | leverage.safer | safer = prevent errors; resilient = recover from errors |
| **leverage.portable** | leverage.composable | composable = combine with others; portable = run elsewhere |
| **leverage.configurable** | leverage.evolvable | evolvable = code changes; configurable = runtime changes |
| **leverage.traceable** | leverage.observable | observable = see state; traceable = follow causality |


### 4.3. low-confidence additions (may be subsumed)

| dimension | likely subsumed by |
|-----------|--------------------|
| leverage.scalable | leverage.faster (at scale) |
| leverage.efficient | leverage.faster (resource-aware) |
| leverage.compatible | leverage.composable |
| leverage.secure | leverage.safer |
| leverage.accessible | leverage.simpler |
| leverage.verifiable | leverage.testable (formal) |


---


## 5. recommendations

### 5.1. proposed additions to the 8 dimensions

expand from 8 to 12 core dimensions:

| # | dimension | what effort is reduced |
|---|-----------|----------------------|
| 1 | leverage.faster | time to complete |
| 2 | leverage.simpler | thought cycles required |
| 3 | leverage.safer | risk exposure |
| 4 | leverage.observable | debug/monitor time |
| 5 | leverage.readable | comprehension time |
| 6 | leverage.composable | integration effort |
| 7 | leverage.reusable | rebuild effort |
| 8 | leverage.evolvable | refactor effort |
| **9** | **leverage.testable** | **validation effort** |
| **10** | **leverage.discoverable** | **findability effort** |
| **11** | **leverage.autonomous** | **wait/approval time** |
| **12** | **leverage.predictable** | **anticipation effort** |


### 5.2. optional secondary dimensions

these could be tracked as sub-dimensions or context-specific:

- leverage.resilient (sub of safer)
- leverage.portable (sub of composable)
- leverage.configurable (sub of evolvable)
- leverage.traceable (sub of observable)


---


## 6. open questions

1. should the 8→12 expansion be adopted, or keep 8 and treat new ones as sub-dimensions?
2. how to weight the new dimensions relative to existing ones?
3. are there domain-specific dimensions missing (e.g., for ML, for infrastructure, for data)?
4. should dimensions be grouped into tiers (core vs extended)?


