
# blocker.1

handCoded -> byHand, withTool -> byTool


# blocker.2
  ### 3.3. how to measure decisions.abstracted.perUse ; why
  doesn't this have a perUse.khues.saved (where khues =
  questinos)  ? (also, time.saved.peruse -> peruse.time.saved



# blocker.3

isn't how to measure perTool.failureModes.handled similar to
  measurement of code.paths.saved ?


# blocker.4

perUse.code.lines.saved ; perUse.code.paths.saved ; also,
possible to measure perUse.code.blocks.saved instead of lines
 saved? (block = a distinct paragraph of code, with or
without comments?)


# blocker.5

> so... do we need code.lines if we have code.blocks?

> isn't cognitive.offloaded === khues.saved ?

> edgecases.covered and hazards.prevented = code.paths saved
?

> perUse.configs.handled === khues.saved?

> perUse.dependencies.wired === code.blocks.saved ?


# blocker.6

| **perTool.failures.handled** | count | failure scenarios handled automatically |


no longer a thing right? since its covered by perUse.code.paths.saved ?


# blocker.7

distill both of these down into orthogonal , fundamental metrics. less is more. full coverage, but maximally distilled, just like we just did with leverage.authorable


    ### 2.2. leverage.supportable metrics

    | metric                               | unit    | description                                     |
    | ------------------------------------ | ------- | ----------------------------------------------- |
    | **perTool.failures.handled**         | count   | failure scenarios handled automatically         |
    | **perTool.code.paths.hidden**        | count   | implementation branches maintainer doesn't see  |
    | **perTool.logpoints.provided**       | count   | observability hooks included by default         |
    | **perTool.traceability.depth**       | levels  | how deep causality can be traced                |
    | **perTool.recovery.mechanisms**      | count   | built-in recovery/retry/rollback capabilities   |
    | **perTool.invariants.enforced**      | count   | correctness guarantees maintained automatically |
    | **perTool.stateTransitions.managed** | count   | state changes handled automatically             |
    | **perIncident.debug.hours.saved**    | hours   | time saved when investigating issues            |
    | **perIncident.mttr.reduction**       | minutes | mean-time-to-recovery improvement               |
    | **perTool.regressionRisk.reduction** | %       | probability reduction of reintroducing bugs     |


    ### 2.3. leverage.adoptable metrics

    | metric                             | unit  | description                              |
    | ---------------------------------- | ----- | ---------------------------------------- |
    | **perTool.domain.depth**           | level | how broadly applicable (see scale below) |
    | **perTool.learning.hours**         | hours | time to productive first use             |
    | **perTool.integration.hours**      | hours | time to integrate into existing codebase |
    | **perTool.usecases.applicable**    | count | distinct scenarios where tool applies    |
    | **perTool.prerequisites.required** | count | dependencies/knowledge needed before use |
    | **perYear.breaking.changes**       | count | backwards-incompatible changes annually  |
    | **perVersion.upgrade.hours**       | hours | effort to upgrade to new version         |
    | **perTool.composition.partners**   | count | other tools it composes well with        |
    | **perTool.migration.hours**        | hours | effort to migrate away if needed         |
    | **perTool.documentation.coverage** | %     | percentage of features documented        |


---

# blocker.8

perIncident -> perFail

---

# blocker.9

isn't perTool.complexity.hidden === perUse.code.paths.saved ?

seems like
- authorship metrics already cover the authorship benefit of complexity hidden in perUse.code.paths.asved

and

| **perIncident.time.saved** | hours | time saved during incidents ("fast to fix") |

already coveres the beenfit of complexity.hidden via its impact on perIncident.time.saved

---

# blocker.10

| **perTool.signals.provided** | count | observability hooks - logs, traces, alerts ("first to know") |
| **perTool.safeguards.provided** | count | recovery mechanisms, invariants, guarantees ("last to fail") |


seems like these are both perUse; each time that tool is used within code (e.g., withSimpleCache is used), it
- provides signals
- provides safeguards

# nitpick.11

should we also track perUse.failsafes.provided? i.e.,
  failsafes and safeguards are both independnetly valuable

> maybe perUse.defences.provided (failsafes, safeguards)
which help produce a pit-of-success

# blocker.12

> perTool.scope.breadth -> perTool.adoption.range ?


# blocker.13

lets have clearer units



## 2. absolute measurement units

### 2.1. leverage.authorable metrics

| metric                       | unit    | description                                                                         |
| ---------------------------- | ------- | ----------------------------------------------------------------------------------- |
| **perUse.time.saved**        | minutes | wall-clock time saved per usage vs by-hand                                          |
| **perUse.code.blocks.saved** | count   | logical code paragraphs you don't write (includes dependency wiring)                |
| **perUse.code.paths.saved**  | count   | conditional branches you don't write (includes edge cases, error handling, hazards) |
| **perUse.khues.saved**       | count   | questions/decisions the tool answers for you (includes configs, cognitive load)     |


### 2.2. leverage.supportable metrics

"fast to fix, first to know, last to fail"

| metric                    | unit  | description                                                        |
| ------------------------- | ----- | ------------------------------------------------------------------ |
| **perFail.time.saved**    | hours | time saved during incidents ("fast to fix")                        |
| **perUse.signals.added**  | count | observability hooks - logs, traces, alerts ("first to know")       |
| **perUse.defences.added** | count | safeguards + failsafes that create pit-of-success ("last to fail") |


### 2.3. leverage.adoptable metrics

| metric                     | unit  | description                                                                      |
| -------------------------- | ----- | -------------------------------------------------------------------------------- |
| **perTool.adoption.range** | level | how broadly applicable ("where can I use it?") - see domain depth scale          |
| **perTool.adoption.hours** | hours | one-time cost to adopt ("how hard to start?") - learning + integration + prereqs |



scope = perUse | perFail | perTool
- perUse = when you use it (execute by codegen, execute in runtime, etc)
- perFail = when a failure occurs (and you must diagnose)
- perTool = once per tool, e.g., at discovery time


then,

metric =
- authorable
  - time
  - code.blocks
  - code.paths
  - khues
- supportable
  - time
  - signals
  - defences
- adoptable
  - range
  - time

then
- polarity =
  - save
  - gain
  - cost

then
- units
  - time (hrs, mins, etc)
  - code.blocks
  - code.paths
  - khues
  - signals
  - defences

i.e.,

leverage.author.time = save(5-hrs/use)
leverage.author.code.path = save(3-paths/use)
leverage.author.code.block = save(10-blocks/use)
leverage.author.khue = save(7-khues/use)

leverage.support.time = save(30-min/fail)
leverage.support.signal = gain(5-signals/use)
leverage.support.defence = gain(7-defences/use)

leverage.adopt.time = cost(5-min/tool) = how long it takes to learn (usually, 0, with robot:brain.repl)
leverage.adopt.range = $depth = how broadly this applies, via depth

---

# blocker.14

actually, should we have a

leverage.adopt.freq = how frequently this tool would be considered for adoption

i.e., how often the usecase that this tool solves occurs in use

right now, we had "range" declared,  but it seems like we're really just trying to measure "freq"

e.g., times per week

so that we can later scale how many uses per week this tool would be adopted in authorship

and later compose an ultimate composite utility value
